{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Transformer Encoder model"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["\n","import numpy as np \n","import pandas as pd\n","import tensorflow as tf \n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def one_hot_encode_tags(data):\n","    data['tags'] = data['tags'].astype(str)\n","    temp_str = [x.split() for x in data.tags]\n","    data['tags'] = temp_str\n","    mlb = MultiLabelBinarizer(sparse_output=True)\n","    temp_data = data.join(\n","                pd.DataFrame.sparse.from_spmatrix(\n","                mlb.fit_transform(data.pop('tags')),\n","                index=data.index,\n","                columns=mlb.classes_))\n","    return temp_data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dtype = {\n","    'answered_correctly': 'int8',\n","    # 'row_id': 'int64',\n","    # 'timestamp': 'int64',\n","    'user_id': 'int32',\n","    'content_id': 'int16',\n","    # 'content_type_id': 'int8',\n","    'task_container_id': 'int16',\n","    # 'user_answer': 'int8',\n","    'prior_question_elapsed_time': 'float32',\n","    # 'prior_question_had_explanation': 'boolean'\n","}\n","\n","dtype_questions = {\n","    'question_id': 'int32',\n","    # 'bundle_id': 'int32',\n","    # 'correct_answer': 'int8',\n","    'part': 'int8',\n","    'tags': 'str',\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv(\n","    '/kaggle/input/riiid-test-answer-prediction/train.csv',\n","    usecols=dtype.keys(),\n","    dtype=dtype\n",")\n","df = df[df.answered_correctly!=-1]\n","df = df.groupby('user_id').head(1500)\n","\n","questions = pd.read_csv(\n","    '/kaggle/input/riiid-test-answer-prediction/questions.csv', \n","    dtype=dtype_questions,\n","    usecols=dtype_questions.keys(),\n","    index_col='question_id'\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Basic transformation functions"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for column in questions.columns:\n","    if column !='part': \n","        questions[column]+=1\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def transform_questions(questions):\n","  part_ids = questions.part.max()+1\n","  return questions, part_ids\n","\n","\n","def transform_df(df, questions):\n","    df['prior_question_elapsed_time'] = df['prior_question_elapsed_time'].fillna(0).astype(np.float32)/300000\n","    content_ids = questions.index.max()+2\n","    df = df.join(questions, on='content_id')\n","    df['content_id'] += 1\n","    df['task_container_id'] += 1\n","    \n","    task_container_ids = 10001\n","    return df, content_ids, task_container_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["questions, part_ids = transform_questions(questions)\n","df, content_ids, task_container_ids = transform_df(df, questions)\n","df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = {uid: u.drop(columns='user_id') for uid, u in df.groupby('user_id')}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","def rolling_window(a, w):\n","    s0, s1 = a.strides\n","    m, n = a.shape\n","    return np.lib.stride_tricks.as_strided(\n","        a, \n","        shape=(m-w+1, w, n), \n","        strides=(s0, s0, s1)\n","    )\n","\n","\n","def make_time_series(x, windows_size):\n","  x = np.pad(x, [[ windows_size-1, 0], [0, 0]], constant_values=0)\n","  x = rolling_window(x, windows_size)\n","  return x\n","\n","\n","def add_features_to_user(user):\n","    # We add one to the column in order to have zeros as padding values\n","    # Start Of Sentence (SOS) token will be 3. \n","    user['answered_correctly'] = user['answered_correctly'].shift(fill_value=2)+1\n","    return user\n","\n","\n","class RiidSequence(tf.keras.utils.Sequence):\n","\n","  def __init__(self, \n","               users, \n","               windows_size,\n","               batch_size=256,\n","               start=0,\n","               end=None):\n","    self.users = users # {'user_id': user_df, ...}\n","    self.windows_size = windows_size\n","    # to convert indices to our keys\n","    self.mapper = dict(zip(range(len(users)), users.keys()))\n","    # start and end to easy generate training and validation\n","    self.start = start\n","    self.end = end if end else len(users)\n","    # To know where the answered_correctly_column is\n","    self.answered_correctly_index = list(self.user_example().columns).index('answered_correctly')\n","        \n","  def __len__(self):\n","    return self.end-self.start\n","\n","  def __getitem__(self, idx):\n","    uid = self.mapper[idx+self.start]\n","    user = self.users[uid].copy()\n","    y = user['answered_correctly'].to_numpy().copy()\n","    x = add_features_to_user(user)\n","    return make_time_series(x, self.windows_size), y\n","\n","  def user_example(self):\n","    uid = self.mapper[self.start]\n","    return add_features_to_user(self.users[uid].copy())\n","\n","  # INFERENCE PART    \n","  def get_user_for_inference(self, user_row):\n","    uid = user_row[self.answered_correctly_index]\n","    user_row[self.answered_correctly_index] = 2 # SOS token\n","    user_row = user_row[np.newaxis, ...]\n","    if uid in self.users:\n","      x = np.concatenate([self.users[uid], user_row])\n","      # same as in training, we need to add one!!!\n","      x[:, self.answered_correctly_index] = np.roll(x[:, self.answered_correctly_index], 1) + 1\n","    else:\n","      x = user_row\n","     \n","    if x.shape[0] < self.windows_size:\n","      return np.pad(x, [[self.windows_size-x.shape[0], 0], [0, 0]])\n","    elif x.shape[0] > self.windows_size:\n","      return x[-self.windows_size:]\n","    else:\n","      return x\n","\n","  def update_user(self, uid, user):\n","    if uid in self.users:\n","      self.users[uid] = \\\n","        np.concatenate([self.users[uid], user])[-self.windows_size:]\n","    else:\n","      self.users[uid] = user"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["RiidSequence(df, 64).user_example().head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x, y = RiidSequence(df, 64)[0]\n","x.shape, y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_angles(pos, i, d_model):\n","  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n","  return pos * angle_rates\n","\n","\n","def positional_encoding(position, d_model):\n","  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                          np.arange(d_model)[np.newaxis, :],\n","                          d_model)\n","  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","  pos_encoding = angle_rads[np.newaxis, ...]\n","\n","  return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","# NN THINGS\n","def scaled_dot_product_attention(q, k, v, mask):\n","  matmul_qk = tf.matmul(q, k, transpose_b=True)\n","  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","  if mask is not None:\n","    scaled_attention_logits += (mask * -1e9)  \n","  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","  output = tf.matmul(attention_weights, v)\n","  return output, attention_weights\n","\n","    \n","class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads):\n","    super(MultiHeadAttention, self).__init__()\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","    \n","    assert d_model % self.num_heads == 0\n","    \n","    self.depth = d_model // self.num_heads\n","    \n","    self.wq = tf.keras.layers.Dense(d_model)\n","    self.wk = tf.keras.layers.Dense(d_model)\n","    self.wv = tf.keras.layers.Dense(d_model)\n","    \n","    self.dense = tf.keras.layers.Dense(d_model)\n","\n","  def split_heads(self, x, batch_size):\n","    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","  def call(self, v, k, q, mask):\n","    batch_size = tf.shape(q)[0]\n","    q = self.wq(q)\n","    k = self.wk(k)\n","    v = self.wv(v)\n","\n","    q = self.split_heads(q, batch_size)\n","    k = self.split_heads(k, batch_size)\n","    v = self.split_heads(v, batch_size)\n","\n","    scaled_attention, attention_weights = scaled_dot_product_attention(\n","        q, k, v, mask)\n","\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","    concat_attention = tf.reshape(scaled_attention, \n","                                  (batch_size, -1, self.d_model))\n","\n","    output = self.dense(concat_attention)\n","\n","    return output, attention_weights\n","\n","\n","def point_wise_feed_forward_network(d_model, dff):\n","  return tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),\n","      tf.keras.layers.Dense(d_model)\n","  ])\n","\n","\n","class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(EncoderLayer, self).__init__()\n","\n","    self.mha = MultiHeadAttention(d_model, num_heads)\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","\n","  def call(self, x, training, mask):\n","\n","    attn_output, _ = self.mha(x, x, x, mask) \n","    attn_output = self.dropout1(attn_output, training=training)\n","    out1 = self.layernorm1(x + attn_output) \n","\n","    ffn_output = self.ffn(out1)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","    out2 = self.layernorm2(out1 + ffn_output) \n","\n","    return out2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_padding_mask(seqs):\n","  # We mask only those vectors of the sequence in which we have all zeroes \n","  # (this is more scalable for some situations).\n","  mask = tf.cast(tf.reduce_all(tf.math.equal(seqs, 0), axis=-1), tf.float32)\n","  return mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["columns = list(RiidSequence(df, 64).user_example().columns)\n","columns"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_series_model(\n","        n_features,\n","        content_ids,\n","        task_container_ids,\n","        part_ids,\n","        windows_size=64,\n","        d_model=24,\n","        num_heads=4,\n","        n_encoder_layers = 2\n","    ):\n","    # Input\n","    inputs = tf.keras.Input(shape=(windows_size, n_features), name='inputs')\n","    mask = create_padding_mask(inputs)\n","    pos_enc = positional_encoding(windows_size, d_model)    \n","    \n","    # Divide branches\n","    content_id = inputs[..., 0]\n","    task_container_id = inputs[..., 1]\n","    answered_correctly = inputs[..., 2]\n","    elapsed_time = inputs[..., 3]\n","    part = inputs[..., 4]\n","    \n","    # Create embeddings\n","    content_embeddings = tf.keras.layers.Embedding(content_ids, d_model)(content_id)\n","    task_embeddings = tf.keras.layers.Embedding(task_container_ids, d_model)(task_container_id)\n","    answered_correctly_embeddings = tf.keras.layers.Embedding(4, d_model)(answered_correctly)\n","    \n","    \n","    # Continuous! Only a learnable layer for it.\n","    elapsed_time_embeddings = tf.keras.layers.Dense(d_model, use_bias=False)(elapsed_time)\n","    part_embeddings = tf.keras.layers.Embedding(part_ids, d_model)(part)\n","    \n","    # Add embeddings\n","    x = tf.keras.layers.Add()([\n","        pos_enc,\n","        content_embeddings,\n","        task_embeddings,\n","        answered_correctly_embeddings,\n","        elapsed_time_embeddings,\n","        part_embeddings,\n","    ])\n","\n","    for _ in range(n_encoder_layers):\n","        x = EncoderLayer(d_model=d_model, num_heads=num_heads, dff=d_model*4, rate=0.1)(x, mask=mask)\n","\n","    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n","    x = tf.keras.layers.Dropout(0.2)(x)    \n","    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(x)\n","    return tf.keras.Model(inputs, output, name='model')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_idx = int(len(df)*0.8)\n","windows_size = 64\n","epochs = 10\n","patience = 2\n","d_model = 32\n","num_heads = 4\n","n_encoder_layers = 2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["s_train = RiidSequence(df, windows_size, start=0, end=train_idx)\n","s_val = RiidSequence(df, windows_size, start=train_idx)\n","\n","n_features = s_train[0][0].shape[-1]\n","\n","tf.keras.backend.clear_session()\n","model = get_series_model(\n","        n_features,\n","        content_ids,\n","        task_container_ids,\n","        part_ids,\n","        windows_size=windows_size,\n","        d_model=d_model,\n","        num_heads=num_heads,\n","        n_encoder_layers=n_encoder_layers\n","    )\n","\n","model.compile(\n","    optimizer='adam', \n","    loss='binary_crossentropy', \n","    metrics=[tf.keras.metrics.AUC(name='AUC'), tf.keras.metrics.BinaryAccuracy(name='acc')]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tf.keras.utils.plot_model(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.fit(\n","    s_train,\n","    validation_data=s_val,\n","    epochs=epochs,\n","    workers=4,\n","    shuffle=True,\n","    use_multiprocessing=True,\n","    callbacks=tf.keras.callbacks.EarlyStopping(patience=patience, monitor='val_AUC', mode='max', restore_best_weights=True),\n","    verbose=1\n",")\n","model.save_weights('model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import gc"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["del s_val\n","del df\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv(\n","    '../input/riiid-test-answer-prediction/train.csv',\n","    usecols=dtype.keys(),\n","    dtype=dtype\n",")\n","df = df[df.answered_correctly!=-1]\n","df = df.groupby('user_id').tail(windows_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df, _, _ = transform_df(df, questions)\n","df = {uid: u.drop(columns='user_id') for uid, u in df.groupby('user_id')}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import riiideducation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["env = riiideducation.make_env()\n","iter_test = env.iter_test()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["columns[columns.index('answered_correctly')] = 'user_id'\n","columns = [c for c in columns if c not in questions.columns] + ['row_id']\n","columns"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for test, sample_prediction in iter_test:\n","    \n","    try:\n","        prior_correct = eval(test['prior_group_answers_correct'].iloc[0])\n","        prior_correct = [a for a in prior_correct if a != -1]\n","    except:\n","        prior_correct = []\n","    \n","    # Add prior correct to test and update stored users\n","    if prior_correct:\n","        prior_test.insert(s_train.answered_correctly_index, 'answered_correctly', prior_correct)\n","        for uid, user in prior_test.groupby('user_id'):\n","            s_train.update_user(\n","                uid, user.drop(columns='user_id').to_numpy())\n","\n","    # Filter test\n","    test = test.loc[\n","        test['content_type_id'] == 0,\n","        columns\n","    ]\n","\n","    # Add global features\n","    test, _, _ = transform_df(test, questions)\n","\n","    # Save test for later\n","    prior_test = test.drop(columns='row_id').copy()\n","\n","    # Make x\n","    x = np.apply_along_axis(\n","        s_train.get_user_for_inference,\n","        1,\n","        test.drop(columns='row_id').to_numpy()\n","    )\n","\n","    # Predict\n","    test['answered_correctly'] = model.predict(x, batch_size=x.shape[0])\n","    \n","    env.predict(test[['row_id', 'answered_correctly']])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":4}